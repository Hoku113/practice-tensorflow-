{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sounds Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the name of the class with the top score when mean-aggregated across frames.\n",
    "def class_names_from_csv(class_map_csv_text):\n",
    "    \"\"\"Returns list of class names corresponding to score vector\"\"\"\n",
    "    class_names = []\n",
    "    with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            class_names.append(row['display_name'])\n",
    "    \n",
    "    return class_names\n",
    "\n",
    "class_map_path = model.class_map_path().numpy()\n",
    "class_names = class_names_from_csv(class_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired_sample_rate parameter is a very important for model result\n",
    "def ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate=16000):\n",
    "    \"\"\"Resample waveform if required\"\"\"\n",
    "    if original_sample_rate != desired_sample_rate:\n",
    "        desired_length = int(round(float(len(waveform)) / original_sample_rate * desired_sample_rate))\n",
    "        waveform = scipy.signal.resample(waveform, desired_length)\n",
    "    return desired_sample_rate, waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and setup soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux command\n",
    "\n",
    "`curl -0 https://storage.googleapis.com/audioset/speech_whistling2.wav`\n",
    "\n",
    "`curl -0 https://storage.googleapis.com/audioset/miaow_16k.wav`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav_file_name = 'speech_whistling2.wav'\n",
    "wav_file_name = 'miaow_16k.wav'\n",
    "sample_rate, wav_data = wavfile.read(wav_file_name, 'rb')\n",
    "sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
    "\n",
    "# Show some basic information about the audio\n",
    "duration = len(wav_data) / sample_rate\n",
    "print(f'Sample rate: {sample_rate} Hz')\n",
    "print(f'Total duration: {duration: .2f}s')\n",
    "print(f'Size of the input: {len(wav_data)}')\n",
    "\n",
    "# Listening to the wav file\n",
    "Audio(wav_data, rate=sample_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = wav_data / tf.int16.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model, check the output\n",
    "scores, embeddings, spectrogram = model(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_np = scores.numpy()\n",
    "spectrogram_np = spectrogram.numpy()\n",
    "infered_class = class_names[scores_np.mean(axis=0).argmax()]\n",
    "print(f'The main sound is: {infered_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(waveform)\n",
    "plt.xlim([0, len(waveform)])\n",
    "\n",
    "# Plot the log_mel spectrogram (returned by the model)\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(spectrogram_np.T, aspect='audio', interpolation='nearest', origin='lower')\n",
    "\n",
    "# Plot and label the model output scores for the top_scoriing classes\n",
    "mean_scores = np.mean(scores, axis=0)\n",
    "top_n = 10\n",
    "top_class_indices = np.argsort(mean_scores)[::-1][:top_n]\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(scores_np[:, top_class_indices].T, aspect='auto', interpolation='nearest', cmap='gray_r')\n",
    "\n",
    "# patch_padding = (PATCH_WINDOW_SECONDS / 2) / PATCH_HOP_SECONDS\n",
    "# values from the model documentation\n",
    "patch_padding = (0.025 / 2) / 0.01\n",
    "plt.xlim([-patch_padding-0.5, scores.shape[0] + patch_padding-0.5])\n",
    "\n",
    "# Label the top_N classes\n",
    "yticks = range(0, top_n, 1)\n",
    "plt.yticks(yticks, [class_names[top_class_indices[x]] for x in yticks] )\n",
    "_ = plt.ylim(-0.5, + np.array([top_n, 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc688668df90e2da2c6fe127a4fae0fc63e05cce4be11dcfea3b7cd731a68cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
