{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pich detection using SPICE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メモ: あとでmusic21, pydubのインストールをしておくこと"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from librosa import display as librosadisplay\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import statistics\n",
    "import sys\n",
    "\n",
    "from IPython.display import Audio, Javascript\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from base64 import b64decode\n",
    "\n",
    "import music21\n",
    "from pydub import AudioSegment\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "print(f'tensorflow: {tf.__verson__}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JS code\n",
    "RECORD = \"\"\"\n",
    "const sleep = time => new Promise(resolve => setTimeout(resolve, time))\n",
    "const b2text = blob => new Promise(resolve => {\n",
    "    const reader = new FileReader()\n",
    "    reader.onloadend = e => resolve(e.srcElement.result)\n",
    "    reader.readAsDataURL(blob)\n",
    "})\n",
    "var record = time => new Promise(async resolve => {\n",
    "    stream = await navigator.mediaDevices.getUserMedia({audio: true})\n",
    "    recorder = new MediaRecorder(stream)\n",
    "    chunks = []\n",
    "    recorder.ondataavailable = e => chunks.push(e.data)\n",
    "    recorder.start()\n",
    "    await sleep(time)\n",
    "    recorder.onstop = async ()=>{\n",
    "        blob = new Blob(chunks)\n",
    "        text = await b2text(blob)\n",
    "        resolve(text)\n",
    "    }\n",
    "    recorder.stop()\n",
    "})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(sec=5):\n",
    "    try:\n",
    "        from google.colab import output\n",
    "    except ImportError:\n",
    "        print('no possible to import output from google.colab')\n",
    "        return\n",
    "    else:\n",
    "        print('Recording')\n",
    "        display(Javascript(RECORD))\n",
    "        s = output.eval_js('record(%d)' % (sec*1000))\n",
    "        fname = 'recorded_audio.wav'\n",
    "        print('Saving to', fname)\n",
    "        b = b64decode(s.split(',')[1])\n",
    "        with open(fname, 'wb') as f:\n",
    "            f.write(b)\n",
    "        return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input your audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SOURCE = 'https://storage.googleapis.com/download.tensorflow.org/data/c-scale-metronome.wav'\n",
    "\n",
    "print(f'You selected {INPUT_SOURCE}')\n",
    "\n",
    "if INPUT_SOURCE == 'RECORD':\n",
    "    uploaded_file_name = record(5)\n",
    "elif INPUT_SOURCE == 'UPLOAD':\n",
    "    try:\n",
    "        from google.colab import files\n",
    "    except ImportError:\n",
    "        print(\"ImportError: files from google.colab seems to not be available\")\n",
    "    else:\n",
    "        uploaded = files.upload()\n",
    "        for fn in uploaded.keys():\n",
    "            print(f'User uploaded file {fn} with length {len(uploaded[fn])} bytes')\n",
    "        uploaded_file_name = next(iter(uploaded))\n",
    "        print(f'Uploaded file: {uploaded_file_name}')\n",
    "\n",
    "elif INPUT_SOURCE.startswith('./drive/'):\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "    except ImportError:\n",
    "        print(\"ImportError: files from google.colab seems to not be available\")\n",
    "    else:\n",
    "        drive.mount('/content/drive')\n",
    "    # don't forget to change the name of the file you will you here!\n",
    "    gdrive_audio_file = 'your audio file here'\n",
    "    uploaded_file_Name = INPUT_SOURCE\n",
    "elif INPUT_SOURCE.startswith('http'):\n",
    "    # wget --no-check-certificate 'https://storage.googleapis.com/download.tensorflow.org/data/c-scale-metronome.wav' -O c-scale.wav\n",
    "    uploaded_file_name = 'c-scale.wav'\n",
    "else:\n",
    "    print('Unrecognized input format!')\n",
    "    print('Please select \"RECORD\", \"UPLOAD\", or specify a file hosted on Google Drive or a file from the web to download file to download')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that converts the user-created audio to the format that the model\n",
    "expects: bitrate 16kHz and only one channel (mono)\n",
    "\"\"\"\n",
    "\n",
    "EXPECTED_SAMPLE_RATE = 16000 # 16kHz\n",
    "\n",
    "def convert_audio_for_model(user_file, output_file='converted_audio_file.wav'):\n",
    "    audio = AudioSegment.from_file(user_file)\n",
    "    audio = audio.set_frame_rate(EXPECTED_SAMPLE_RATE).set_channels(1)\n",
    "    audio.export(output_file, format=\"wav\")\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Converting to the expected format for the model\n",
    "in all the input 4 input method before, the uploaded file name is at \n",
    "the variable uploaded_file_name\n",
    "\"\"\"\n",
    "converted_audio_file = convert_audio_for_model(uploaded_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading audio samples from the wav file\n",
    "sample_rate, audio_samples = wavfile.read(converted_audio_file, 'rb')\n",
    "\n",
    "# Show some basic information about the audio\n",
    "duration = len(audio_samples) / sample_rate\n",
    "print(f'sampele rate: {sample_rate} Hz')\n",
    "print(f'Total duration: {duration:.2f}s')\n",
    "print(f'Size of the input: {len(audio_samples)}')\n",
    "\n",
    "# Listen to the wav file\n",
    "Audio(audio_samples, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visalize the audio as a waveform\n",
    "_ = plt.plot(audio_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ABS_INT16 = 32768.0\n",
    "\n",
    "\n",
    "def plot_stft(x, sample_rate, show_black_and_white=False):\n",
    "    x_stft = np.abs(librosa.stft(x, n_fft=2048))\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(20, 10)\n",
    "    x_stft_db = librosa.amplitude_to_db(x_stft, ref=np.max)\n",
    "    if show_black_and_white:\n",
    "        librosadisplay.specshow(data=x_stft_db, y_axis='log',\n",
    "                                sr=sample_rate, cmap='gray_r')\n",
    "    else:\n",
    "        librosadisplay.specshow(data=x_stft_db, y_axis='log', sr=sample_rate)\n",
    "\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "\n",
    "plot_stft(audio_samples / MAX_ABS_INT16 , sample_rate=EXPECTED_SAMPLE_RATE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_samples = audio_samples / float(MAX_ABS_INT16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executed the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the SPICE model is easy:\n",
    "model = hub.load(\"https://tfhub.dev/google/spice/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now feed the audio to the SPICE tf.hub model to obtain pitch and uncertainty outputs as tensors\n",
    "model_output = model.signatures['serving_default'](tf.constant(audio_samples, tf.float32))\n",
    "\n",
    "pitch_outputs = model_output['pitch']\n",
    "uncertainty_outputs = model_output['uncertainty']\n",
    "\n",
    "# Uncertainty basically means the inverse of confidence.\n",
    "confidence_outputs = 1.0 - uncertainty_outputs\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 10)\n",
    "plt.plot(pitch_outputs, label='pitch')\n",
    "plt.plot(confidence_outputs, label='confidence')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show graph(drawing confidence < 0.9)\n",
    "confidence_outputs = list(confidence_outputs)\n",
    "pitch_outputs = [float(x) for x in pitch_outputs]\n",
    "\n",
    "indices = range(len(pitch_outputs))\n",
    "confident_pitch_outputs = [(i, p)\n",
    "    for i, p, c in zip(indices, pitch_outputs, confidence_outputs) if c >= 0.9]\n",
    "confident_pitch_outputs_x, confident_pitch_outputs_y = zip(*confident_pitch_outputs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_SIZE_inches(20, 10)\n",
    "ax.set_ylim([0, 1])\n",
    "plt.scatter(confident_pitch_outputs_x, confident_pitch_outputs_y)\n",
    "plt.scatter(confident_pitch_outpus_x, confident_pitch_outputs_y, c=\"r\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
