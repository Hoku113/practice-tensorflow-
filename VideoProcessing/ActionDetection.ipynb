{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action detection by 3DCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0, Setup\n",
    "\n",
    "if you are not install these module, you must write in following these command on PowerShell or Cmd\n",
    "\n",
    "```\n",
    "pip install -q imageio\n",
    "pip install -q opencv-python\n",
    "pip install -q git+https://github.com/tensorflow/docs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_docs.vis import embed\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "import ssl\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "from IPython import display\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1, Create helper function for UCF101 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCF_ROOT = 'https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/'\n",
    "_VIDEO_LIST = None\n",
    "_CACHE_DIR = tempfile.mkdtemp()\n",
    "\n",
    "unverified_context = ssl._create_unverified_context()\n",
    "\n",
    "# ucfのビデオデータセットを読み込んでリストとして格納する\n",
    "def list_ucf_videos():\n",
    "    \"\"\"LIsts videos available in UCF101 dataset\"\"\"\n",
    "    global _VIDEO_LIST\n",
    "    if not _VIDEO_LIST:\n",
    "        index = request.urlopen(UCF_ROOT, context=unverified_context).read().decode(\"utf-8\")\n",
    "        videos = re.findall(\"(v_[\\w_]+\\.avi)\", index)\n",
    "        _VIDEO_LIST = sorted(set(videos))\n",
    "    return list(_VIDEO_LIST)\n",
    "\n",
    "# ビデオデータをフェッチキャッシュしてローカルファイルに保存する\n",
    "def fetch_ucf_video(video):\n",
    "    \"\"\"Fetchs a video and cache into local filesystem\"\"\"\n",
    "    cache_path = os.path.join(_CACHE_DIR, video)\n",
    "    if not os.path.exists(cache_path):\n",
    "        urlpath = request.urljoin(UCF_ROOT, video)\n",
    "        print(f\"Fetching {urlpath} => {cache_path}\")\n",
    "        data = request.urlopen(urlpath, context=unverified_context).read()\n",
    "        open(cache_path, \"wb\").write(data)\n",
    "    return cache_path\n",
    "\n",
    "# フレームの中心から一定の距離離れている部分までを正方形に切り取る\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y:start_y+min_dim, start_x:start_x+min_dim]\n",
    "\n",
    "# 一フレームずつごとに切り出して1~0までの行列に画像を変換させる\n",
    "def load_video(path, max_frames=0, resize=(224, 224)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames) / 255.0\n",
    "\n",
    "# 画像データをgit形式にして保存する\n",
    "def to_gif(images):\n",
    "    converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "    imageio.mimsave('./animation.gif', converted_images, fps=25)\n",
    "    return embed.embed_file('./animation.gif')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the kinetics-400 action labels from the GitHub repository.\n",
    "KINETICS_URL = \"https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt\"\n",
    "with request.urlopen(KINETICS_URL) as obj:\n",
    "    labels = [line.decode(\"utf-8\").strip() for line in obj.readlines()]\n",
    "\n",
    "print(f\"Found {len(labels)} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf_videos = list_ucf_videos()\n",
    "\n",
    "categories = {}\n",
    "for video in ucf_videos:\n",
    "  category = video[2:-12]\n",
    "  if category not in categories:\n",
    "    categories[category] = []\n",
    "  categories[category].append(video)\n",
    "print(\"Found %d videos in %d categories.\" % (len(ucf_videos), len(categories)))\n",
    "\n",
    "for category, sequences in categories.items():\n",
    "  summary = \", \".join(sequences[:2])\n",
    "  print(\"%-20s %4d videos (%s, ...)\" % (category, len(sequences), summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample cricket video\n",
    "video_path = fetch_ucf_video(\"v_CricketShot_g04_c02.avi\")\n",
    "sample_video = load_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i3d = hub.load(\"https://tfhub.dev/deepmind/i3d-kinetics-400/1\").signatures['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample_video):\n",
    "    # Add a batch axis  to the sample video\n",
    "    model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "    logits = i3d(model_input)['default'][0]\n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "    print(\"Top 5 actions:\")\n",
    "    for i in np.argsort(probabilities)[::-1][:5]:\n",
    "        print(f\"{labels[i]:22}: {probabilities[i] * 100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(sample_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.check_call(\"curl -O https://upload.wikimedia.org/wikipedia/commons/8/86/End_of_a_jam.ogv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"End_of_a_jam.ogv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_video = load_video(video_path[:100])\n",
    "sample_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_gif(sample_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(sample_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc688668df90e2da2c6fe127a4fae0fc63e05cce4be11dcfea3b7cd731a68cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
