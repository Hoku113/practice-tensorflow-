{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice GAN usgin tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import imageio\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_docs.vis import embed\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from IPython import display\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" We could retrieve this value from module.get_input_shapes() if we didn't know\n",
    "    beforehand which module we will be using\"\"\"\n",
    "\n",
    "latent_dim = 512\n",
    "\n",
    "\"\"\"\n",
    "Interpolates between two vectors that are non-zero and don't both lie on a \n",
    "line going through origin. First normalizes v2 to have the same norm as v1.\n",
    "Then interpolates between the tow vectors on the hypersphere.\n",
    "\"\"\"\n",
    "\n",
    "def interpolate_hypersphere(v1, v2, num_steps):\n",
    "    v1_norm = tf.norm(v1)\n",
    "    v2_norm = tf.norm(v2)\n",
    "    v2_normalzied = v2 * (v1_norm / v2_norm)\n",
    "\n",
    "    vectors = []\n",
    "    for step in range(num_steps):\n",
    "        interpolated = v1 + (v2_normalzied - v1) * step / (num_steps - 1)\n",
    "        interpolated_norm = tf.norm(interpolated)\n",
    "        interpolated_normalized = interpolated * (v1_norm / interpolated_norm)\n",
    "        vectors.append(interpolated_normalized)\n",
    "    return tf.stack(vectors)\n",
    "\n",
    "# simple way to display an image\n",
    "def display_image(image):\n",
    "    image = tf.constant(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "    return PIL.Image.fromarray(image.numpy())\n",
    "\n",
    "# Given a set of images, show an animation\n",
    "def animate(images):\n",
    "    images = np.array(images)\n",
    "    converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "    imageio.mimsave('./animation.gif', converted_images)\n",
    "    return embed.embed_file('./animation.gif')\n",
    "\n",
    "logging.set_verbosity(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GAN model\n",
    "progan = hub.load(\"https://tfhub.dev/google/progan-128/1\").signatures['default']\n",
    "\n",
    "progan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_between_vectors():\n",
    "    v1 = tf.random.normal([latent_dim])\n",
    "    v2 = tf.random.normal([latent_dim])\n",
    "\n",
    "    # Creates a tensor with 25 steps of interpolation between v1 and v2.\n",
    "    vectors = interpolate_hypersphere(v1, v2, 50)\n",
    "\n",
    "    # Uses module to generate images from the latent space.\n",
    "    interpolated_images = progan(vectors)['default']\n",
    "\n",
    "    return interpolated_images\n",
    "\n",
    "interpolated_images = interpolate_between_vectors()\n",
    "animate(interpolated_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_from_module_space = True\n",
    "\n",
    "def get_module_space_image():\n",
    "    vector = tf.random.normal([1, latent_dim])\n",
    "    images = progan(vector)['default'][0]\n",
    "    return images\n",
    "\n",
    "def upload_image():\n",
    "    uploaded = files.upload()\n",
    "    image = imageio.imread(uploaded[list(uploaded.keys())[0]])\n",
    "    return transform.resize(image, [128, 128])\n",
    "\n",
    "if image_from_module_space:\n",
    "    target_image = get_module_space_image()\n",
    "else:\n",
    "    target_image = upload_image()\n",
    "\n",
    "display_image(target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "initial_vector = tf.random.normal([1, latent_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(progan(initial_vector)['default'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最も近いベクトルを見つける\n",
    "def find_closest_latent_vector(initial_vector, num_optimization_steps,steps_per_image):\n",
    "    images = []\n",
    "    losses = []\n",
    "\n",
    "    vector = tf.Variable(initial_vector)\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "    loss_fn = tf.losses.MeanAbsoluteError(reduction=\"sum\")\n",
    "\n",
    "    for step in range(num_optimization_steps):\n",
    "        if step % 100 == 0:\n",
    "            print()\n",
    "\n",
    "        print('.', end='')\n",
    "        with tf.GradientTape() as tape:\n",
    "            image = progan(vector.read_value())['default'][0]\n",
    "            if step % steps_per_image == 0:\n",
    "                images.append(image.numpy())\n",
    "            target_image_difference = loss_fn(image, target_image[:,:,:3])            \n",
    "            \"\"\"\n",
    "            The latent vectors were sampled from a normal distribution. We can get\n",
    "            more realistic images if we regularize the length of the latent vector to \n",
    "            the average length of vector from this distribution\n",
    "            \"\"\"\n",
    "            regularizer = tf.abs(tf.norm(vector) - np.sqrt(latent_dim))\n",
    "\n",
    "            loss = target_image_difference + regularizer\n",
    "            losses.append(loss.numpy())\n",
    "        grads = tape.gradient(loss, [vector])\n",
    "        optimizer.apply_gradients(zip(grads, [vector]))\n",
    "\n",
    "    return images, losses\n",
    "\n",
    "num_optimization_steps=200\n",
    "steps_per_image = 5\n",
    "images, loss = find_closest_latent_vector(initial_vector, num_optimization_steps, steps_per_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot Loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.ylim([0, max(plt.ylim())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate(np.stack(images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37cba68cc0666ff0500346fbbc272670c42c6c1b2383619b4dcb2ba70df940d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
