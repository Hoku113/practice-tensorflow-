{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweak the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependency module\n",
    "```\n",
    "pip install --user-deprecated=legacy-resolver tflite-model-maker\n",
    "pip install -U tensorflow-datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow_examples.lite.model_maker.core.export_format import ExportFormat\n",
    "from tensorflow_examples.lite.model_maker.core.task import image_preprocessing\n",
    "\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker import ImageClassifierDataLoader\n",
    "from tflite_model_maker.image_classifier import ModelSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds_name = \"cassava\"\n",
    "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
    "    name=tfds_name,\n",
    "    split=['train', 'validation', 'test'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "TFLITE_NAME_PREFIX = tfds_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In following this code has executed when you will try model training using original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root_dir = tf.keras.utils.get_file(\n",
    "#     'cassavaleafdata.zip',\n",
    "#     'https://storage.googleapis.com/emcassavadata/cassavaleafdata.zip',\n",
    "#     extract=True\n",
    "# )\n",
    "\n",
    "# data_root_dir = os.path.splittext(data_root_dir)[0]\n",
    "\n",
    "# builder = tfds.ImageFolder(data_root_dir)\n",
    "\n",
    "# ds_info = builder.info\n",
    "# ds_train = builder.as_dataset(split='train', as_supervised=True)\n",
    "# ds_validation = builder.as_dataset(split='validation', as_supervised=True)\n",
    "# ds_test = builder.as_dataset(split='test', as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize train_split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add unknown tfds datasets\n",
    "\n",
    "It means creating a model that returns the \"Unknown\" label \\\n",
    "if something  unexpected is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKNOWN_TFDS_DATASETS = [{\n",
    "    'tfds_name': 'imagenet_v2/matched-frequency',\n",
    "    'train_split': 'test[:80%]',\n",
    "    'test_split': 'test[80%]',\n",
    "    'num_examples_ratio_to_normal': 1.0,\n",
    "},\n",
    "{\n",
    "    'tfds_name': 'oxford_flowers102',\n",
    "    'train_split': 'train',\n",
    "    'test_split': 'test',\n",
    "    'num_examples_ratio_to_normal': 1.0,\n",
    "},\n",
    "{\n",
    "    'tfds_name': 'beams',\n",
    "    'train_split': 'train',\n",
    "    'test_split' : 'test',\n",
    "    'num_examples_ratio_to_normal' : 1.0,\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unknown datasets\n",
    "weights = [\n",
    "    spec['num_examples_ratio_to_normal'] for spec in UNKNOWN_TFDS_DATASETS\n",
    "]\n",
    "\n",
    "num_unknown_train_examples = sum(\n",
    "    int(w * ds_train.cardinality().numpy()) for w in weights)\n",
    "ds_unknown_train = tf.data.Dataset.sample_from_datasets([\n",
    "    tfds.load(name=spec['tfds_name'], split=spec['train_split'],\n",
    "              as_supervised=True).repeat(-1) for spec in UNKNOWN_TFDS_DATASETS\n",
    "], weights).take(num_unknown_train_examples)\n",
    "ds_unknown_train = ds_unknown_train.apply(\n",
    "    tf.data.experimential.assert_cardinality(num_unknown_train_examples))\n",
    "ds_unknown_tests = [\n",
    "    tfds.load(name=spec['tfds_name'], split=spec['test_split'], as_supervised=True) for spec in UNKNOWN_TFDS_DATASETS\n",
    "]\n",
    "ds_unknown_test = ds_unknown_tests[0]\n",
    "for ds in ds_unknown_tests[1:]:\n",
    "    ds_unknown_test = ds_unknown_test.concatenate(ds)\n",
    "\n",
    "# All examples from the unknown datasets will get a new class label number\n",
    "num_normal_classes = len(ds_info.features['label'].names)\n",
    "unknown_label_value = tf.convert_to_tensor(num_normal_classes, tf.int64)\n",
    "ds_unknown_train = ds_unknown_train.map(\n",
    "    lambda image, _: (image, unknown_label_value))\n",
    "ds_uknown_test = ds_unknown_test.map(\n",
    "    lambda image, _: (image, unknown_label_value))\n",
    "\n",
    "# Merge the normal train dataset with the unknown train dataset.\n",
    "weights = [\n",
    "    ds_train.cardinality().numpy(),\n",
    "    ds_unknown_train.cardinality().numpy()\n",
    "]\n",
    "\n",
    "ds_train_with_unknown = tf.data.Dataset.sample_from_datasets(\n",
    "    [ds_train, ds_unknown_train], [float(w) for w in weights])\n",
    "ds_train_with_unknown = ds_train_with_unknown.apply(\n",
    "    tf.data.experimental.assert_cardinality(sum(weights)))\n",
    "\n",
    "print(f\"\"\"Added {ds_unknown_train.cardinality().numpy()} negative examples. \\n\n",
    "      Training dataset ha now {ds_train_with_unknown.cardinality().numpy()}examples in total\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply expantion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop_and_random_augmentations_fn(image):\n",
    "    # preprocess_for_train does random crop and resize internally.\n",
    "    image = image_preprocessing.preprocess_for_train(image)\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "    image = tf.image.random_contrast(image, 0.5, 2.0)\n",
    "    image = tf.image.random_saturation(image, 0.75, 1.25)\n",
    "    image = tf.image.random_hue(image, 0.1)\n",
    "    return image\n",
    "\n",
    "def random_crop_fn(image):\n",
    "    # preprocess_for_train does random crop and resize internally\n",
    "    image = image_preprocessing.preprocess_for_train(image)\n",
    "    return image\n",
    "\n",
    "def resize_and_center_crop_fn(image):\n",
    "    image = tf.image.resize(image, (256, 256))\n",
    "    image = image[16:240, 16:240]\n",
    "    return image\n",
    "\n",
    "no_augment_fn = lambda image: image\n",
    "\n",
    "train_augment_fn = lambda image, label:(random_crop_and_random_augmentations_fn(image), label)\n",
    "eval_augment_fn = lambda image, label: (resize_and_center_crop_fn(image), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_with_unknown = ds_train_with_unknown.map(train_augment_fn)\n",
    "ds_validation = ds_validation.map(eval_augment_fn)\n",
    "ds_test = ds_test.map(eval_augment_fn)\n",
    "ds_unknown_test = ds_unknown_test.map(eval_augment_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ds_info.features['label'].names + ['UNKNOWN']\n",
    "\n",
    "train_data = ImageClassifierDataLoader(ds_train_with_unknown, ds_train_with_unknown.cardinality(), label_names)\n",
    "\n",
    "validation_data = ImageClassifierDataLoader(ds_validation, ds_validation.cardinality(), label_names)\n",
    "\n",
    "test_data = ImageClassifierDataLoader(ds_test, ds_test.cardinality(), label_names)\n",
    "\n",
    "unknown_test_data = ImageClassifierDataLoader(ds_unknown_test, ds_unknown_test.cardinality(), label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mobilenet_v3_large_100_224'\n",
    "map_model_name = {\n",
    "    'cropnet_cassava': 'https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1',\n",
    "    'cropnet_concat': 'https://tfhub.dev/google/cropnet/feature_vector/concat/1',\n",
    "    'cropnet_image_net': 'https://tfhub.dev/google/cropnet/feature_vector/imagenet/1',\n",
    "    'mobilenet_v3_large_100_224': 'https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5'\n",
    "}\n",
    "\n",
    "model_handle = map_model_name[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model maker\n",
    "image_model_spec = ModelSpec(uri=model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = image_classifier.create(\n",
    "    train_data, \n",
    "    model_spec=image_model_spec,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.01\n",
    "    epochs=5,\n",
    "    shuffle=True,\n",
    "    train_whole_model=True # Tweak the base model during training\n",
    "    validation_data=validation_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More analyis\n",
    "def predict_class_label_number(dataset):\n",
    "    \"\"\"Runs inference and returns predictions as class label numbers\"\"\"\n",
    "    rev_label_names = {l: i for i, l in enumerate(label_names)}\n",
    "    return [\n",
    "        rev_label_names[o[0][0]] for o in model.predict_top_k(dataset, batch_size=128)\n",
    "    ]\n",
    "\n",
    "def show_confusion_matrix(cm,labels):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, xticklabels=labels, yticklabels=labels, annot=True, fmt='g')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(\n",
    "    list(ds_test.map(lambda x, y: y)),\n",
    "    predict_class_label_number(test_data),\n",
    "    num_classes=len(label_names)\n",
    ")\n",
    "\n",
    "show_confusion_matrix(confusion_mtx, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check mdoel (Using unknown data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(unknown_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_confusion_mtx = tf.math.confusion_matrix(\n",
    "    list(ds_unknown_test.map(lambda x, y: y)),\n",
    "    predict_class_label_number(unknown_test_data),\n",
    "    num_classes=len(label_names)\n",
    ")\n",
    "\n",
    "shwo_confusion_matrix(unknown_confusion_mtx, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model as TFLite and SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_filename = f'{TFLITE_NAME_PREFIX}_model_{model_name}.tflite'\n",
    "model.export(export_dir='.', tflite_filename-tflite_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export saved model version\n",
    "model.export(export_dir='.', export_format=Exportformat.SAVED_MDOEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc688668df90e2da2c6fe127a4fae0fc63e05cce4be11dcfea3b7cd731a68cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
