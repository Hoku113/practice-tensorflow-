{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Model re training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.9.1\n",
      "Hub version: 0.12.0\n",
      "GPU is Not available\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(f\"TF version: {tf.__version__}\")\n",
    "print(f\"Hub version: {hub.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"Not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model select (already training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4 with input size (224, 224)\n"
     ]
    }
   ],
   "source": [
    "module_selection = (\"mobilenet_v2_100_224\", 224)\n",
    "handle_base, pixels = module_selection\n",
    "MODULE_HANDLE = f\"https://tfhub.dev/google/imagenet/{handle_base}/feature_vector/4\"\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(f\"Using {MODULE_HANDLE} with input size {IMAGE_SIZE}\")\n",
    "\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up flower dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228813984/228813984 [==============================] - 173s 1us/step\n"
     ]
    }
   ],
   "source": [
    "data_dir = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SetUp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 731 images belonging to 5 classes.\n",
      "Found 2939 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
    "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "                       interpolation='bilinear')\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **datagen_kwargs\n",
    ")                   \n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs\n",
    ") \n",
    "\n",
    "do_data_augmentation = False\n",
    "if do_data_augmentation:\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=0.2, height_shift_range=0.2,\n",
    "        shear_range=0.2, zoom_range=0.2\n",
    "        **datagen_kwargs\n",
    "    )\n",
    "else:\n",
    "    train_datagen = valid_datagen\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 6405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 6,405\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "do_fine_tuning = False\n",
    "\n",
    "print(f\"Building model with {MODULE_HANDLE}\")\n",
    "model = tf.keras.Sequential([\n",
    "    # Explicitly define the input shape so the model can be properly\n",
    "    # loaded by the TFLiteConverter\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3, )),\n",
    "    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hokuto\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this training program recommends running on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=validation_steps\n",
    ").history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss (training and validation)\")\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylim([0, 2])\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy (training and validation)\")\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylim([0, 1])\n",
    "plt.plot(hist[\"accuracy\"])\n",
    "plt.plot(hist[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_string_from_index(index):\n",
    "    for class_string, class_index in valid_generator.class_indices.items():\n",
    "        if class_index == index:\n",
    "            return class_string\n",
    "\n",
    "x, y = next(valid_generator)\n",
    "image = x[0, :, :, :]\n",
    "true_index = np.argmax(y[0])\n",
    "\n",
    "### 気になった変数を表示する用\n",
    "print(x)\n",
    "print(y)\n",
    "print(true_index)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Expand the validation image to (1, 224, 224, 3) before predicting the label\n",
    "prediction_scores = model.predict(np.expand_dims(image, axis=0))\n",
    "predicted_index = np.argmax(prediction_scores)\n",
    "print(f\"True label: {get_class_string_from_index(true_index)}\")\n",
    "print(f\"Predicted label: {get_class_string_from_index(predicted_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = \"./MLmodel\"\n",
    "tf.saved_model.save(model, saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc688668df90e2da2c6fe127a4fae0fc63e05cce4be11dcfea3b7cd731a68cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
